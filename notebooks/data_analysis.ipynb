{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49924a39",
   "metadata": {},
   "source": [
    "# Robot CN Network - Data Analysis\n",
    "\n",
    "This notebook provides tools for analyzing collected demonstration data and training results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a55489",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from pathlib import Path\n",
    "\n",
    "from robot_cn_network.data import RobotDataset\n",
    "from robot_cn_network.utils import load_dataset, compute_metrics\n",
    "from robot_cn_network.models import ACTPolicy, ModelConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d43d68db",
   "metadata": {},
   "source": [
    "## Load and Analyze Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df7ac43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load demonstration data\n",
    "data_path = \"../data/demonstrations\"\n",
    "dataset = RobotDataset(data_path, sequence_length=1, action_horizon=10)\n",
    "\n",
    "print(f\"Dataset size: {len(dataset)} samples\")\n",
    "print(f\"Number of episodes: {len(dataset.episodes)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df881a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze action distributions\n",
    "all_actions = []\n",
    "for episode in dataset.episodes:\n",
    "    actions = [step['action'] for step in episode]\n",
    "    all_actions.extend(actions)\n",
    "\n",
    "all_actions = np.array(all_actions)\n",
    "\n",
    "fig, axes = plt.subplots(2, 4, figsize=(15, 8))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i in range(min(7, all_actions.shape[1])):\n",
    "    axes[i].hist(all_actions[:, i], bins=50, alpha=0.7)\n",
    "    axes[i].set_title(f'Action Dimension {i}')\n",
    "    axes[i].set_xlabel('Value')\n",
    "    axes[i].set_ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bba2cc0",
   "metadata": {},
   "source": [
    "## Training Progress Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a972b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and visualize training logs (if available)\n",
    "import json\n",
    "import os\n",
    "\n",
    "log_path = \"../outputs/training/training_log.json\"\n",
    "if os.path.exists(log_path):\n",
    "    with open(log_path, 'r') as f:\n",
    "        logs = json.load(f)\n",
    "    \n",
    "    epochs = [log['epoch'] for log in logs]\n",
    "    train_losses = [log['train_loss'] for log in logs]\n",
    "    val_losses = [log.get('val_loss') for log in logs if 'val_loss' in log]\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(epochs, train_losses, label='Training Loss')\n",
    "    if val_losses:\n",
    "        val_epochs = [log['epoch'] for log in logs if 'val_loss' in log]\n",
    "        plt.plot(val_epochs, val_losses, label='Validation Loss')\n",
    "    \n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training Progress')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No training logs found. Run training first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5692af59",
   "metadata": {},
   "source": [
    "## Model Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97d3ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load trained model and analyze\n",
    "model_path = \"../outputs/training/best_model.pth\"\n",
    "if os.path.exists(model_path):\n",
    "    checkpoint = torch.load(model_path, map_location='cpu')\n",
    "    \n",
    "    print(\"Model checkpoint info:\")\n",
    "    print(f\"Epoch: {checkpoint.get('epoch', 'N/A')}\")\n",
    "    print(f\"Validation Loss: {checkpoint.get('metadata', {}).get('val_loss', 'N/A')}\")\n",
    "    \n",
    "    # Count parameters\n",
    "    total_params = sum(p.numel() for p in checkpoint['model_state_dict'].values())\n",
    "    print(f\"Total parameters: {total_params:,}\")\n",
    "else:\n",
    "    print(\"No trained model found. Run training first.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
